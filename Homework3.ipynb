{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from easydict import EasyDict as edict\n",
    "import mindspore.nn as nn\n",
    "from mindspore import context\n",
    "import mindspore.dataset.engine as de\n",
    "import mindspore.common.dtype as mstype\n",
    "from mindspore.mindrecord import FileWriter\n",
    "from mindspore.common.parameter import Parameter\n",
    "import mindspore.dataset.transforms.c_transforms as deC\n",
    "from mindspore.common.tensor import Tensor\n",
    "from mindspore.nn.optim import Adam\n",
    "from mindspore.train.model import Model\n",
    "from mindspore.train.loss_scale_manager import DynamicLossScaleManager\n",
    "from mindspore.train.callback import CheckpointConfig, ModelCheckpoint\n",
    "from mindspore.train.callback import Callback, TimeMonitor\n",
    "from mindspore.train.serialization import load_checkpoint, load_param_into_net\n",
    "from src import tokenization\n",
    "from src.train_util import LossCallBack\n",
    "from src.lr_schedule import create_dynamic_lr\n",
    "from src.transformer_model import TransformerConfig, TransformerModel\n",
    "from src.data_utils import create_training_instance, write_instance_to_file\n",
    "from src.transformer_for_train import TransformerTrainOneStepWithLossScaleCell,TransformerTrainOneStepCell,TransformerNetworkWithLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# running mode\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"CPU\")\n",
    "# data process params\n",
    "data_cfg = edict({\n",
    "    'input_file': './data/ch_en_all.txt',\n",
    "    'vocab_file': './data/ch_en_vocab.txt',\n",
    "    'train_file_mindrecord': './data/train.mindrecord',\n",
    "    'eval_file_mindrecord': './data/test.mindrecord',\n",
    "    'train_file_source': './data/source_train.txt',\n",
    "    'eval_file_source': './data/source_test.txt',\n",
    "    'num_splits': 1,\n",
    "    'clip_to_max_len': False,\n",
    "    'max_seq_length': 40\n",
    "})\n",
    "\n",
    "# data preprocessing function\n",
    "def data_prepare(cfg, eval_idx):\n",
    "    tokenizer = tokenization.WhiteSpaceTokenizer(vocab_file=cfg.vocab_file)\n",
    "\n",
    "    writer_train = FileWriter(cfg.train_file_mindrecord, cfg.num_splits)\n",
    "    writer_eval = FileWriter(cfg.eval_file_mindrecord, cfg.num_splits)\n",
    "\n",
    "    data_schema = {\"source_sos_ids\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "                   \"source_sos_mask\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "                   \"source_eos_ids\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "                   \"source_eos_mask\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "                   \"target_sos_ids\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "                   \"target_sos_mask\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "                   \"target_eos_ids\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "                   \"target_eos_mask\": {\"type\": \"int32\", \"shape\": [-1]}\n",
    "                   }\n",
    "\n",
    "    writer_train.add_schema(data_schema, \"tranformer train\")\n",
    "    writer_eval.add_schema(data_schema, \"tranformer eval\")\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    f_train = open(cfg.train_file_source, 'w', encoding='utf-8')\n",
    "    f_test = open(cfg.eval_file_source, 'w', encoding='utf-8')\n",
    "    f = open(cfg.input_file, \"r\", encoding='utf-8')\n",
    "\n",
    "    for s_line in f:\n",
    "        print(\"finish {}/{}\".format(index, 23607), end='\\r')\n",
    "\n",
    "        line = tokenization.convert_to_unicode(s_line)\n",
    "        source_line, target_line = line.strip().split(\"\\t\")\n",
    "        source_tokens = tokenizer.tokenize(source_line)\n",
    "        target_tokens = tokenizer.tokenize(target_line)\n",
    "\n",
    "        if len(source_tokens) >= (cfg.max_seq_length - 1) or len(target_tokens) >= (cfg.max_seq_length - 1):\n",
    "            if cfg.clip_to_max_len:\n",
    "                source_tokens = source_tokens[:cfg.max_seq_length - 1]\n",
    "                target_tokens = target_tokens[:cfg.max_seq_length - 1]\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        index = index + 1\n",
    "        # print(source_tokens)\n",
    "        instance = create_training_instance(source_tokens, target_tokens, cfg.max_seq_length)\n",
    "\n",
    "        if index in eval_idx:\n",
    "            f_test.write(s_line)\n",
    "            features = write_instance_to_file(writer_eval, instance, tokenizer, cfg.max_seq_length)\n",
    "        else:\n",
    "            f_train.write(s_line)\n",
    "            features = write_instance_to_file(writer_train, instance, tokenizer, cfg.max_seq_length)\n",
    "\n",
    "    f.close()\n",
    "    f_test.close()\n",
    "    f_train.close()\n",
    "    writer_train.commit()\n",
    "    writer_eval.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish 23607/23607\r"
     ]
    }
   ],
   "source": [
    "# test data (20%)\n",
    "sample_num = 23607\n",
    "eval_idx = np.random.choice(sample_num, int(sample_num * 0.2), replace=False)\n",
    "data_prepare(data_cfg, eval_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# data loading function\n",
    "def load_dataset(batch_size=1, data_file=None):\n",
    "    ds = de.MindDataset(data_file,\n",
    "                        columns_list=[\"source_eos_ids\", \"source_eos_mask\",\n",
    "                                      \"target_sos_ids\", \"target_sos_mask\",\n",
    "                                      \"target_eos_ids\", \"target_eos_mask\"],\n",
    "                        shuffle=False)\n",
    "    type_cast_op = deC.TypeCast(mstype.int32)\n",
    "    ds = ds.map(input_columns=\"source_eos_ids\", operations=type_cast_op)\n",
    "    ds = ds.map(input_columns=\"source_eos_mask\", operations=type_cast_op)\n",
    "    ds = ds.map(input_columns=\"target_sos_ids\", operations=type_cast_op)\n",
    "    ds = ds.map(input_columns=\"target_sos_mask\", operations=type_cast_op)\n",
    "    ds = ds.map(input_columns=\"target_eos_ids\", operations=type_cast_op)\n",
    "    ds = ds.map(input_columns=\"target_eos_mask\", operations=type_cast_op)\n",
    "    # apply batch operations\n",
    "    ds = ds.batch(batch_size, drop_remainder=True)\n",
    "    ds.channel_name = 'transformer'\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(4146:140294278549888,MainProcess):2022-03-24-18:04:15.927.13 [mindspore/dataset/engine/datasets_standard_format.py:221] WARN: global shuffle is not used.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[40], dtype=Int32, value= [3983,    3,    2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0, \n",
       "    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test data\n",
    "next(load_dataset(data_file=data_cfg.train_file_mindrecord).create_dict_iterator())['source_eos_ids'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_cfg = edict({\n",
    "    #--------------------------------------nework config-------------------------------------\n",
    "    'transformer_network': 'base',\n",
    "    'init_loss_scale_value': 1024,\n",
    "    'scale_factor': 2,\n",
    "    'scale_window': 2000,\n",
    "    'lr_schedule': edict({\n",
    "        'learning_rate': 1.0,\n",
    "        'warmup_steps': 8000,\n",
    "        'start_decay_step': 16000,\n",
    "        'min_lr': 0.0,\n",
    "    }),\n",
    "    #-----------------------------------save model config-------------------------\n",
    "    'enable_save_ckpt': True,\n",
    "    #Enable save checkpointdefault is true.\n",
    "    'save_checkpoint_steps': 590,\n",
    "    'save_checkpoint_num': 2,\n",
    "    #Save checkpoint steps, default is 590.\n",
    "    #Save checkpoint numbers, default is 2.\n",
    "    'save_checkpoint_path': './checkpoint',\n",
    "    #Save checkpoint file path,default is ./checkpoint/\n",
    "    'save_checkpoint_name': 'transformer-32_40',\n",
    "    'checkpoint_path': '',\n",
    "    #Checkpoint file path\n",
    "    #-------------------------------device config-----------------------------\n",
    "    'enable_data_sink': False,\n",
    "    #Enable data sink, default is False.\n",
    "    'device_id': 0,\n",
    "    'device_num': 1,\n",
    "    'distribute': False,\n",
    "    # -----------------mast same with the dataset-----------------------\n",
    "    'seq_length': 40,\n",
    "    'vocab_size': 10067,\n",
    "    #--------------------------------------------------------------------------\n",
    "    'data_path': \"./data/train.mindrecord\",\n",
    "    #Data path\n",
    "    'epoch_size': 15,\n",
    "    'batch_size': 32,\n",
    "    'max_position_embeddings': 40,\n",
    "    'enable_lossscale': False,\n",
    "    'do_shuffle': True\n",
    "    #Use lossscale or not, default is False.\n",
    "    #Enable shuffle for dataset, default is True.\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# network params\n",
    "if train_cfg.transformer_network == 'base':\n",
    "    transformer_net_cfg = TransformerConfig(\n",
    "        batch_size=train_cfg.batch_size,\n",
    "        seq_length=train_cfg.seq_length,\n",
    "        vocab_size=train_cfg.vocab_size,\n",
    "        hidden_size=512,\n",
    "        num_hidden_layers=6,\n",
    "        num_attention_heads=8,\n",
    "        intermediate_size=2048,\n",
    "        hidden_act=\"relu\",\n",
    "        hidden_dropout_prob=0.2,\n",
    "        attention_probs_dropout_prob=0.2,\n",
    "        max_position_embeddings=train_cfg.max_position_embeddings,\n",
    "        initializer_range=0.02,\n",
    "        label_smoothing=0.1,\n",
    "        input_mask_from_dataset=True,\n",
    "        dtype=mstype.float32,\n",
    "        compute_type=mstype.float16)\n",
    "elif train_cfg.transformer_network == 'large':\n",
    "    transformer_net_cfg = TransformerConfig(\n",
    "        batch_size=train_cfg.batch_size,\n",
    "        seq_length=train_cfg.seq_length,\n",
    "        vocab_size=train_cfg.vocab_size,\n",
    "        hidden_size=1024,\n",
    "        num_hidden_layers=6,\n",
    "        num_attention_heads=16,\n",
    "        intermediate_size=4096,\n",
    "        hidden_act=\"relu\",\n",
    "        hidden_dropout_prob=0.2,\n",
    "        attention_probs_dropout_prob=0.2,\n",
    "        max_position_embeddings=train_cfg.max_position_embeddings,\n",
    "        initializer_range=0.02,\n",
    "        label_smoothing=0.1,\n",
    "        input_mask_from_dataset=True,\n",
    "        dtype=mstype.float32,\n",
    "        compute_type=mstype.float16)\n",
    "else:\n",
    "    raise Exception(\n",
    "        \"The src/train_confige of transformer_network must base or large.Change the str/train_confige file and try again!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define training function\n",
    "def train(cfg):\n",
    "    train_dataset = load_dataset(cfg.batch_size, data_file=cfg.data_path)\n",
    "    netwithloss = TransformerNetworkWithLoss(transformer_net_cfg, True)\n",
    "\n",
    "    if cfg.checkpoint_path:\n",
    "        parameter_dict = load_checkpoint(cfg.checkpoint_path)\n",
    "        load_param_into_net(netwithloss, parameter_dict)\n",
    "\n",
    "    lr = Tensor(create_dynamic_lr(schedule=\"constant*rsqrt_hidden*linear_warmup*rsqrt_decay\",\n",
    "                                  training_steps=train_dataset.get_dataset_size() * cfg.epoch_size,\n",
    "                                  learning_rate=cfg.lr_schedule.learning_rate,\n",
    "                                  warmup_steps=cfg.lr_schedule.warmup_steps,\n",
    "                                  hidden_size=transformer_net_cfg.hidden_size,\n",
    "                                  start_decay_step=cfg.lr_schedule.start_decay_step,\n",
    "                                  min_lr=cfg.lr_schedule.min_lr), mstype.float32)\n",
    "    optimizer = Adam(netwithloss.trainable_params(), lr)\n",
    "    callbacks = [TimeMonitor(train_dataset.get_dataset_size()), LossCallBack()]\n",
    "\n",
    "    if cfg.enable_save_ckpt:\n",
    "        ckpt_config = CheckpointConfig(save_checkpoint_steps=cfg.save_checkpoint_steps,\n",
    "                                       keep_checkpoint_max=cfg.save_checkpoint_num)\n",
    "        ckpoint_cb = ModelCheckpoint(prefix=cfg.save_checkpoint_name,\n",
    "                                     directory=cfg.save_checkpoint_path, config=ckpt_config)\n",
    "        callbacks.append(ckpoint_cb)\n",
    "\n",
    "    if cfg.enable_lossscale:\n",
    "        scale_manager = DynamicLossScaleManager(init_loss_scale=cfg.init_loss_scale_value,\n",
    "                                                scale_factor=cfg.scale_factor,\n",
    "                                                scale_window=cfg.scale_window)\n",
    "        update_cell = scale_manager.get_update_cell()\n",
    "        netwithgrads = TransformerTrainOneStepWithLossScaleCell(netwithloss,\n",
    "                                                                optimizer=optimizer, scale_update_cell=update_cell)\n",
    "    else:\n",
    "        netwithgrads = TransformerTrainOneStepCell(netwithloss, optimizer=optimizer)\n",
    "\n",
    "    netwithgrads.set_train(True)\n",
    "    model = Model(netwithgrads)\n",
    "    model.train(cfg.epoch_size, train_dataset, callbacks=callbacks,\n",
    "                dataset_sink_mode=cfg.enable_data_sink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(4146:140294278549888,MainProcess):2022-03-24-18:05:24.387.28 [mindspore/dataset/engine/datasets_standard_format.py:221] WARN: global shuffle is not used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 20237, epoch: 1, step: 1, outputs are [9.586152]\n",
      "time: 25149, epoch: 1, step: 2, outputs are [9.600659]\n",
      "time: 30327, epoch: 1, step: 3, outputs are [9.707446]\n",
      "time: 35795, epoch: 1, step: 4, outputs are [9.668275]\n",
      "time: 41146, epoch: 1, step: 5, outputs are [9.617159]\n",
      "time: 46372, epoch: 1, step: 6, outputs are [9.6584015]\n",
      "time: 51529, epoch: 1, step: 7, outputs are [9.744037]\n",
      "time: 56917, epoch: 1, step: 8, outputs are [9.557116]\n",
      "time: 62179, epoch: 1, step: 9, outputs are [9.859571]\n",
      "time: 67143, epoch: 1, step: 10, outputs are [9.609059]\n",
      "time: 72161, epoch: 1, step: 11, outputs are [9.642342]\n",
      "time: 77398, epoch: 1, step: 12, outputs are [9.664566]\n",
      "time: 82363, epoch: 1, step: 13, outputs are [9.71799]\n",
      "time: 87773, epoch: 1, step: 14, outputs are [9.692408]\n",
      "time: 93665, epoch: 1, step: 15, outputs are [9.55251]\n",
      "time: 99002, epoch: 1, step: 16, outputs are [9.639153]\n",
      "time: 104089, epoch: 1, step: 17, outputs are [9.598873]\n",
      "time: 109664, epoch: 1, step: 18, outputs are [9.638764]\n",
      "time: 115158, epoch: 1, step: 19, outputs are [9.472846]\n",
      "time: 120786, epoch: 1, step: 20, outputs are [9.670824]\n",
      "time: 125848, epoch: 1, step: 21, outputs are [9.435009]\n",
      "time: 130870, epoch: 1, step: 22, outputs are [9.386255]\n",
      "time: 135935, epoch: 1, step: 23, outputs are [9.468297]\n",
      "time: 140794, epoch: 1, step: 24, outputs are [9.561171]\n",
      "time: 145823, epoch: 1, step: 25, outputs are [9.399307]\n",
      "time: 150842, epoch: 1, step: 26, outputs are [9.367808]\n",
      "time: 155885, epoch: 1, step: 27, outputs are [9.419266]\n",
      "time: 161003, epoch: 1, step: 28, outputs are [9.190037]\n",
      "time: 165901, epoch: 1, step: 29, outputs are [9.209482]\n",
      "time: 170622, epoch: 1, step: 30, outputs are [9.324614]\n",
      "time: 175530, epoch: 1, step: 31, outputs are [9.329563]\n",
      "time: 180523, epoch: 1, step: 32, outputs are [9.506626]\n",
      "time: 185555, epoch: 1, step: 33, outputs are [9.228363]\n",
      "time: 190665, epoch: 1, step: 34, outputs are [9.287214]\n",
      "time: 195634, epoch: 1, step: 35, outputs are [9.082861]\n",
      "time: 200561, epoch: 1, step: 36, outputs are [9.156913]\n",
      "time: 205633, epoch: 1, step: 37, outputs are [9.140641]\n",
      "time: 210702, epoch: 1, step: 38, outputs are [9.002184]\n",
      "time: 215841, epoch: 1, step: 39, outputs are [9.122835]\n",
      "time: 220805, epoch: 1, step: 40, outputs are [8.921314]\n",
      "time: 226109, epoch: 1, step: 41, outputs are [9.152039]\n",
      "time: 231265, epoch: 1, step: 42, outputs are [9.184102]\n",
      "time: 236397, epoch: 1, step: 43, outputs are [8.947017]\n",
      "time: 241635, epoch: 1, step: 44, outputs are [8.96258]\n",
      "time: 246614, epoch: 1, step: 45, outputs are [8.8294525]\n",
      "time: 252110, epoch: 1, step: 46, outputs are [8.703707]\n",
      "time: 258161, epoch: 1, step: 47, outputs are [9.051665]\n",
      "time: 263940, epoch: 1, step: 48, outputs are [8.7266445]\n",
      "time: 269172, epoch: 1, step: 49, outputs are [8.644903]\n",
      "time: 274445, epoch: 1, step: 50, outputs are [8.737856]\n",
      "time: 279658, epoch: 1, step: 51, outputs are [8.486437]\n",
      "time: 285310, epoch: 1, step: 52, outputs are [8.827682]\n",
      "time: 290557, epoch: 1, step: 53, outputs are [8.687574]\n",
      "time: 295727, epoch: 1, step: 54, outputs are [8.597523]\n",
      "time: 301197, epoch: 1, step: 55, outputs are [8.565021]\n",
      "time: 306610, epoch: 1, step: 56, outputs are [8.441724]\n",
      "time: 312006, epoch: 1, step: 57, outputs are [8.353911]\n",
      "time: 316948, epoch: 1, step: 58, outputs are [8.411663]\n",
      "time: 321984, epoch: 1, step: 59, outputs are [8.434421]\n",
      "time: 327258, epoch: 1, step: 60, outputs are [8.425933]\n",
      "time: 332462, epoch: 1, step: 61, outputs are [8.290805]\n",
      "time: 337893, epoch: 1, step: 62, outputs are [8.347125]\n",
      "time: 343149, epoch: 1, step: 63, outputs are [8.345316]\n",
      "time: 348549, epoch: 1, step: 64, outputs are [8.593266]\n",
      "time: 354383, epoch: 1, step: 65, outputs are [8.491673]\n",
      "time: 360032, epoch: 1, step: 66, outputs are [8.42619]\n",
      "time: 365691, epoch: 1, step: 67, outputs are [8.339467]\n",
      "time: 371100, epoch: 1, step: 68, outputs are [8.266435]\n",
      "time: 377041, epoch: 1, step: 69, outputs are [8.067238]\n",
      "time: 382348, epoch: 1, step: 70, outputs are [8.082153]\n",
      "time: 387751, epoch: 1, step: 71, outputs are [8.145675]\n",
      "time: 392787, epoch: 1, step: 72, outputs are [8.208939]\n",
      "time: 397786, epoch: 1, step: 73, outputs are [8.20755]\n",
      "time: 402939, epoch: 1, step: 74, outputs are [8.180846]\n",
      "time: 408099, epoch: 1, step: 75, outputs are [8.062127]\n",
      "time: 413219, epoch: 1, step: 76, outputs are [8.096363]\n",
      "time: 418423, epoch: 1, step: 77, outputs are [8.176239]\n",
      "time: 423490, epoch: 1, step: 78, outputs are [8.4797735]\n",
      "time: 428977, epoch: 1, step: 79, outputs are [8.217917]\n",
      "time: 434189, epoch: 1, step: 80, outputs are [8.351264]\n",
      "time: 439143, epoch: 1, step: 81, outputs are [8.156739]\n",
      "time: 444359, epoch: 1, step: 82, outputs are [8.288969]\n",
      "time: 449245, epoch: 1, step: 83, outputs are [7.901586]\n",
      "time: 454054, epoch: 1, step: 84, outputs are [7.8581]\n",
      "time: 459123, epoch: 1, step: 85, outputs are [7.7162576]\n",
      "time: 464059, epoch: 1, step: 86, outputs are [7.8505516]\n",
      "time: 468823, epoch: 1, step: 87, outputs are [8.045239]\n",
      "time: 474505, epoch: 1, step: 88, outputs are [7.8209605]\n",
      "time: 479598, epoch: 1, step: 89, outputs are [7.9851394]\n",
      "time: 484647, epoch: 1, step: 90, outputs are [7.9020705]\n",
      "time: 489645, epoch: 1, step: 91, outputs are [8.092724]\n",
      "time: 495533, epoch: 1, step: 92, outputs are [7.9939065]\n",
      "time: 501370, epoch: 1, step: 93, outputs are [8.270715]\n",
      "time: 507323, epoch: 1, step: 94, outputs are [7.947619]\n",
      "time: 512837, epoch: 1, step: 95, outputs are [8.001925]\n",
      "time: 517903, epoch: 1, step: 96, outputs are [8.074342]\n",
      "time: 523071, epoch: 1, step: 97, outputs are [8.168042]\n",
      "time: 528170, epoch: 1, step: 98, outputs are [7.670538]\n",
      "time: 533440, epoch: 1, step: 99, outputs are [7.572536]\n",
      "time: 538593, epoch: 1, step: 100, outputs are [7.556637]\n",
      "time: 543679, epoch: 1, step: 101, outputs are [7.5242453]\n",
      "time: 548634, epoch: 1, step: 102, outputs are [7.973786]\n",
      "time: 553525, epoch: 1, step: 103, outputs are [7.855094]\n",
      "time: 558496, epoch: 1, step: 104, outputs are [7.8534513]\n",
      "time: 563239, epoch: 1, step: 105, outputs are [7.803364]\n",
      "time: 568269, epoch: 1, step: 106, outputs are [7.8209896]\n",
      "time: 573379, epoch: 1, step: 107, outputs are [7.7280827]\n",
      "time: 578550, epoch: 1, step: 108, outputs are [7.869213]\n",
      "time: 583887, epoch: 1, step: 109, outputs are [7.939452]\n",
      "time: 589210, epoch: 1, step: 110, outputs are [7.8007283]\n",
      "time: 594178, epoch: 1, step: 111, outputs are [7.9686613]\n",
      "time: 599818, epoch: 1, step: 112, outputs are [7.941861]\n",
      "time: 604774, epoch: 1, step: 113, outputs are [7.9450097]\n",
      "time: 609548, epoch: 1, step: 114, outputs are [7.807731]\n",
      "time: 614523, epoch: 1, step: 115, outputs are [7.4139037]\n",
      "time: 619492, epoch: 1, step: 116, outputs are [7.584982]\n",
      "time: 624755, epoch: 1, step: 117, outputs are [7.4556437]\n",
      "time: 629947, epoch: 1, step: 118, outputs are [7.51542]\n",
      "time: 635085, epoch: 1, step: 119, outputs are [7.7857456]\n",
      "time: 640157, epoch: 1, step: 120, outputs are [7.45542]\n",
      "time: 645378, epoch: 1, step: 121, outputs are [7.637853]\n",
      "time: 650468, epoch: 1, step: 122, outputs are [7.6019597]\n",
      "time: 655795, epoch: 1, step: 123, outputs are [7.631253]\n",
      "time: 661034, epoch: 1, step: 124, outputs are [7.525937]\n",
      "time: 666226, epoch: 1, step: 125, outputs are [7.636415]\n",
      "time: 671364, epoch: 1, step: 126, outputs are [7.866909]\n",
      "time: 676472, epoch: 1, step: 127, outputs are [7.6878405]\n",
      "time: 682045, epoch: 1, step: 128, outputs are [7.7475557]\n",
      "time: 687152, epoch: 1, step: 129, outputs are [7.8516755]\n",
      "time: 692433, epoch: 1, step: 130, outputs are [7.7658277]\n",
      "time: 697407, epoch: 1, step: 131, outputs are [7.6564546]\n",
      "time: 702250, epoch: 1, step: 132, outputs are [7.1970153]\n",
      "time: 707189, epoch: 1, step: 133, outputs are [7.450974]\n",
      "time: 711952, epoch: 1, step: 134, outputs are [7.2793484]\n",
      "time: 716897, epoch: 1, step: 135, outputs are [7.3436055]\n",
      "time: 722299, epoch: 1, step: 136, outputs are [7.5510025]\n",
      "time: 727683, epoch: 1, step: 137, outputs are [7.5021167]\n",
      "time: 732836, epoch: 1, step: 138, outputs are [7.537075]\n",
      "time: 737898, epoch: 1, step: 139, outputs are [7.5505524]\n",
      "time: 742945, epoch: 1, step: 140, outputs are [7.6227913]\n",
      "time: 747749, epoch: 1, step: 141, outputs are [7.5067306]\n",
      "time: 753049, epoch: 1, step: 142, outputs are [7.4958386]\n",
      "time: 758240, epoch: 1, step: 143, outputs are [7.415048]\n",
      "time: 763466, epoch: 1, step: 144, outputs are [7.6856065]\n",
      "time: 768446, epoch: 1, step: 145, outputs are [7.465035]\n",
      "time: 773442, epoch: 1, step: 146, outputs are [7.5508184]\n",
      "time: 778524, epoch: 1, step: 147, outputs are [7.4780526]\n",
      "time: 783387, epoch: 1, step: 148, outputs are [7.544507]\n",
      "time: 788459, epoch: 1, step: 149, outputs are [7.5487175]\n",
      "time: 793510, epoch: 1, step: 150, outputs are [7.6079884]\n",
      "time: 799156, epoch: 1, step: 151, outputs are [7.0482783]\n",
      "time: 804272, epoch: 1, step: 152, outputs are [7.0685763]\n",
      "time: 809418, epoch: 1, step: 153, outputs are [7.206381]\n",
      "time: 814462, epoch: 1, step: 154, outputs are [7.0938373]\n",
      "time: 819634, epoch: 1, step: 155, outputs are [7.2994447]\n",
      "time: 824662, epoch: 1, step: 156, outputs are [7.562429]\n",
      "time: 829495, epoch: 1, step: 157, outputs are [7.285709]\n",
      "time: 834498, epoch: 1, step: 158, outputs are [7.2444587]\n",
      "time: 839672, epoch: 1, step: 159, outputs are [7.4189887]\n",
      "time: 844742, epoch: 1, step: 160, outputs are [7.379059]\n",
      "time: 850089, epoch: 1, step: 161, outputs are [7.412767]\n",
      "time: 855460, epoch: 1, step: 162, outputs are [7.174562]\n",
      "time: 860657, epoch: 1, step: 163, outputs are [7.180884]\n",
      "time: 865871, epoch: 1, step: 164, outputs are [7.5812025]\n",
      "time: 870832, epoch: 1, step: 165, outputs are [7.264647]\n",
      "time: 875856, epoch: 1, step: 166, outputs are [7.313939]\n",
      "time: 881094, epoch: 1, step: 167, outputs are [7.361573]\n",
      "time: 886221, epoch: 1, step: 168, outputs are [7.390118]\n",
      "time: 891210, epoch: 1, step: 169, outputs are [7.356571]\n",
      "time: 896131, epoch: 1, step: 170, outputs are [7.2869678]\n",
      "time: 901060, epoch: 1, step: 171, outputs are [7.2480197]\n",
      "time: 906266, epoch: 1, step: 172, outputs are [6.898026]\n",
      "time: 911345, epoch: 1, step: 173, outputs are [6.9979177]\n",
      "time: 916606, epoch: 1, step: 174, outputs are [7.037655]\n",
      "time: 921803, epoch: 1, step: 175, outputs are [6.9539495]\n",
      "time: 926889, epoch: 1, step: 176, outputs are [7.0212226]\n",
      "time: 932184, epoch: 1, step: 177, outputs are [7.1109314]\n",
      "time: 937304, epoch: 1, step: 178, outputs are [7.2035413]\n",
      "time: 942631, epoch: 1, step: 179, outputs are [7.041137]\n",
      "time: 948274, epoch: 1, step: 180, outputs are [7.327901]\n",
      "time: 953643, epoch: 1, step: 181, outputs are [7.213127]\n",
      "time: 958608, epoch: 1, step: 182, outputs are [7.37732]\n",
      "time: 963901, epoch: 1, step: 183, outputs are [7.165564]\n",
      "time: 969240, epoch: 1, step: 184, outputs are [7.167456]\n",
      "time: 974601, epoch: 1, step: 185, outputs are [7.107036]\n",
      "time: 979676, epoch: 1, step: 186, outputs are [7.318254]\n",
      "time: 984667, epoch: 1, step: 187, outputs are [7.195466]\n",
      "time: 989606, epoch: 1, step: 188, outputs are [7.2662263]\n",
      "time: 994525, epoch: 1, step: 189, outputs are [7.219934]\n",
      "time: 999532, epoch: 1, step: 190, outputs are [7.2980337]\n",
      "time: 1004766, epoch: 1, step: 191, outputs are [7.0295167]\n",
      "time: 1010012, epoch: 1, step: 192, outputs are [6.9247236]\n",
      "time: 1014782, epoch: 1, step: 193, outputs are [6.846871]\n",
      "time: 1020079, epoch: 1, step: 194, outputs are [6.9795427]\n",
      "time: 1025914, epoch: 1, step: 195, outputs are [6.7900357]\n",
      "time: 1032417, epoch: 1, step: 196, outputs are [6.995386]\n",
      "time: 1037699, epoch: 1, step: 197, outputs are [7.2190013]\n",
      "time: 1042593, epoch: 1, step: 198, outputs are [7.166814]\n",
      "time: 1047426, epoch: 1, step: 199, outputs are [7.0508223]\n",
      "time: 1052441, epoch: 1, step: 200, outputs are [6.9920177]\n",
      "time: 1057475, epoch: 1, step: 201, outputs are [7.317261]\n",
      "time: 1062760, epoch: 1, step: 202, outputs are [7.211194]\n",
      "time: 1067810, epoch: 1, step: 203, outputs are [6.932252]\n",
      "time: 1073390, epoch: 1, step: 204, outputs are [6.968277]\n",
      "time: 1078557, epoch: 1, step: 205, outputs are [6.9806232]\n",
      "time: 1083630, epoch: 1, step: 206, outputs are [7.0327487]\n",
      "time: 1088654, epoch: 1, step: 207, outputs are [7.2153196]\n",
      "time: 1093699, epoch: 1, step: 208, outputs are [7.0614]\n",
      "time: 1098900, epoch: 1, step: 209, outputs are [7.198404]\n",
      "time: 1103942, epoch: 1, step: 210, outputs are [7.2218366]\n",
      "time: 1109114, epoch: 1, step: 211, outputs are [7.1700325]\n",
      "time: 1114366, epoch: 1, step: 212, outputs are [7.3177037]\n",
      "time: 1119484, epoch: 1, step: 213, outputs are [6.8164573]\n",
      "time: 1124789, epoch: 1, step: 214, outputs are [6.7944636]\n",
      "time: 1130011, epoch: 1, step: 215, outputs are [6.9026484]\n",
      "time: 1135222, epoch: 1, step: 216, outputs are [6.8543997]\n",
      "time: 1140345, epoch: 1, step: 217, outputs are [6.8096986]\n",
      "time: 1145244, epoch: 1, step: 218, outputs are [7.0437245]\n",
      "time: 1150369, epoch: 1, step: 219, outputs are [6.858654]\n",
      "time: 1155445, epoch: 1, step: 220, outputs are [7.052312]\n",
      "time: 1160435, epoch: 1, step: 221, outputs are [7.0452795]\n",
      "time: 1165602, epoch: 1, step: 222, outputs are [7.208774]\n",
      "time: 1170573, epoch: 1, step: 223, outputs are [7.067006]\n",
      "time: 1175770, epoch: 1, step: 224, outputs are [6.9580183]\n",
      "time: 1180826, epoch: 1, step: 225, outputs are [6.84827]\n",
      "time: 1185906, epoch: 1, step: 226, outputs are [6.8387628]\n",
      "time: 1191157, epoch: 1, step: 227, outputs are [7.1355944]\n",
      "time: 1196260, epoch: 1, step: 228, outputs are [7.1319284]\n",
      "time: 1201201, epoch: 1, step: 229, outputs are [7.080564]\n",
      "time: 1206249, epoch: 1, step: 230, outputs are [7.0049767]\n",
      "time: 1211652, epoch: 1, step: 231, outputs are [7.138361]\n",
      "time: 1217120, epoch: 1, step: 232, outputs are [6.93306]\n",
      "time: 1222526, epoch: 1, step: 233, outputs are [7.046064]\n",
      "time: 1227496, epoch: 1, step: 234, outputs are [6.750559]\n",
      "time: 1232812, epoch: 1, step: 235, outputs are [6.7542553]\n",
      "time: 1237947, epoch: 1, step: 236, outputs are [6.7993736]\n",
      "time: 1242962, epoch: 1, step: 237, outputs are [6.7506056]\n",
      "time: 1247956, epoch: 1, step: 238, outputs are [6.7310023]\n",
      "time: 1252863, epoch: 1, step: 239, outputs are [6.774322]\n",
      "time: 1257853, epoch: 1, step: 240, outputs are [6.789312]\n",
      "time: 1262899, epoch: 1, step: 241, outputs are [7.1358347]\n",
      "time: 1267892, epoch: 1, step: 242, outputs are [7.0816693]\n",
      "time: 1272919, epoch: 1, step: 243, outputs are [7.0127482]\n",
      "time: 1277971, epoch: 1, step: 244, outputs are [6.906113]\n",
      "time: 1283022, epoch: 1, step: 245, outputs are [7.0730805]\n",
      "time: 1288468, epoch: 1, step: 246, outputs are [7.1428957]\n",
      "time: 1293603, epoch: 1, step: 247, outputs are [6.8599987]\n",
      "time: 1298752, epoch: 1, step: 248, outputs are [6.775068]\n",
      "time: 1303849, epoch: 1, step: 249, outputs are [6.759389]\n",
      "time: 1309095, epoch: 1, step: 250, outputs are [6.7552733]\n",
      "time: 1314170, epoch: 1, step: 251, outputs are [7.1976833]\n",
      "time: 1319188, epoch: 1, step: 252, outputs are [6.8038445]\n",
      "time: 1323997, epoch: 1, step: 253, outputs are [6.8782043]\n",
      "time: 1328927, epoch: 1, step: 254, outputs are [6.9468875]\n",
      "time: 1334016, epoch: 1, step: 255, outputs are [6.9542074]\n",
      "time: 1338988, epoch: 1, step: 256, outputs are [6.909997]\n",
      "time: 1344155, epoch: 1, step: 257, outputs are [7.0425525]\n",
      "time: 1349329, epoch: 1, step: 258, outputs are [6.486853]\n",
      "time: 1354594, epoch: 1, step: 259, outputs are [6.528795]\n",
      "time: 1359826, epoch: 1, step: 260, outputs are [6.353769]\n",
      "time: 1365231, epoch: 1, step: 261, outputs are [6.629201]\n",
      "time: 1370719, epoch: 1, step: 262, outputs are [6.5407243]\n",
      "time: 1376826, epoch: 1, step: 263, outputs are [6.8901935]\n",
      "time: 1382124, epoch: 1, step: 264, outputs are [6.871667]\n",
      "time: 1387410, epoch: 1, step: 265, outputs are [6.8750844]\n",
      "time: 1392577, epoch: 1, step: 266, outputs are [6.9921207]\n",
      "time: 1397730, epoch: 1, step: 267, outputs are [6.88428]\n",
      "time: 1403116, epoch: 1, step: 268, outputs are [6.693716]\n",
      "time: 1408370, epoch: 1, step: 269, outputs are [6.748932]\n",
      "time: 1413528, epoch: 1, step: 270, outputs are [6.6382127]\n",
      "time: 1418615, epoch: 1, step: 271, outputs are [6.8348093]\n",
      "time: 1423919, epoch: 1, step: 272, outputs are [6.7445493]\n",
      "time: 1429590, epoch: 1, step: 273, outputs are [6.7786784]\n",
      "time: 1435200, epoch: 1, step: 274, outputs are [6.9978986]\n",
      "time: 1440350, epoch: 1, step: 275, outputs are [6.868019]\n",
      "time: 1445836, epoch: 1, step: 276, outputs are [6.751493]\n",
      "time: 1451007, epoch: 1, step: 277, outputs are [6.515136]\n",
      "time: 1456063, epoch: 1, step: 278, outputs are [6.7555246]\n",
      "time: 1460973, epoch: 1, step: 279, outputs are [6.8506103]\n",
      "time: 1466101, epoch: 1, step: 280, outputs are [6.49955]\n",
      "time: 1471483, epoch: 1, step: 281, outputs are [6.459806]\n",
      "time: 1476703, epoch: 1, step: 282, outputs are [6.530053]\n",
      "time: 1481659, epoch: 1, step: 283, outputs are [6.4581714]\n",
      "time: 1486671, epoch: 1, step: 284, outputs are [6.521658]\n",
      "time: 1491619, epoch: 1, step: 285, outputs are [6.3622203]\n",
      "time: 1496641, epoch: 1, step: 286, outputs are [6.430797]\n",
      "time: 1501667, epoch: 1, step: 287, outputs are [6.4584656]\n",
      "time: 1506713, epoch: 1, step: 288, outputs are [6.794081]\n",
      "time: 1512133, epoch: 1, step: 289, outputs are [6.888524]\n",
      "time: 1517292, epoch: 1, step: 290, outputs are [6.703876]\n",
      "time: 1522860, epoch: 1, step: 291, outputs are [6.672108]\n",
      "time: 1528146, epoch: 1, step: 292, outputs are [6.729943]\n",
      "time: 1533333, epoch: 1, step: 293, outputs are [6.6048255]\n",
      "time: 1538524, epoch: 1, step: 294, outputs are [6.596617]\n",
      "time: 1543665, epoch: 1, step: 295, outputs are [6.9710407]\n",
      "time: 1548878, epoch: 1, step: 296, outputs are [6.870523]\n",
      "time: 1553665, epoch: 1, step: 297, outputs are [6.495885]\n",
      "time: 1558579, epoch: 1, step: 298, outputs are [6.505525]\n",
      "time: 1563450, epoch: 1, step: 299, outputs are [6.5429626]\n",
      "time: 1568507, epoch: 1, step: 300, outputs are [6.68987]\n",
      "time: 1573503, epoch: 1, step: 301, outputs are [6.904024]\n",
      "time: 1578258, epoch: 1, step: 302, outputs are [6.370427]\n",
      "time: 1583391, epoch: 1, step: 303, outputs are [6.792554]\n",
      "time: 1588679, epoch: 1, step: 304, outputs are [6.687414]\n",
      "time: 1593694, epoch: 1, step: 305, outputs are [6.7653875]\n",
      "time: 1599260, epoch: 1, step: 306, outputs are [6.5991383]\n",
      "time: 1604566, epoch: 1, step: 307, outputs are [6.3582306]\n",
      "time: 1609621, epoch: 1, step: 308, outputs are [6.5167737]\n",
      "time: 1614934, epoch: 1, step: 309, outputs are [6.5305824]\n",
      "time: 1620304, epoch: 1, step: 310, outputs are [6.617226]\n",
      "time: 1625531, epoch: 1, step: 311, outputs are [6.75937]\n",
      "time: 1630575, epoch: 1, step: 312, outputs are [6.3304768]\n",
      "time: 1635718, epoch: 1, step: 313, outputs are [6.281265]\n",
      "time: 1640937, epoch: 1, step: 314, outputs are [6.4334583]\n",
      "time: 1646456, epoch: 1, step: 315, outputs are [6.3222384]\n",
      "time: 1652058, epoch: 1, step: 316, outputs are [6.2970624]\n",
      "time: 1658069, epoch: 1, step: 317, outputs are [6.293384]\n",
      "time: 1664343, epoch: 1, step: 318, outputs are [6.4893465]\n",
      "time: 1669616, epoch: 1, step: 319, outputs are [6.5636744]\n",
      "time: 1674776, epoch: 1, step: 320, outputs are [6.6508512]\n",
      "time: 1679967, epoch: 1, step: 321, outputs are [6.519122]\n",
      "time: 1684834, epoch: 1, step: 322, outputs are [6.6390786]\n",
      "time: 1690225, epoch: 1, step: 323, outputs are [6.756152]\n",
      "time: 1695437, epoch: 1, step: 324, outputs are [6.5977225]\n",
      "time: 1700931, epoch: 1, step: 325, outputs are [6.789585]\n",
      "time: 1706199, epoch: 1, step: 326, outputs are [6.833606]\n",
      "time: 1711165, epoch: 1, step: 327, outputs are [6.3385754]\n",
      "time: 1716504, epoch: 1, step: 328, outputs are [6.48206]\n",
      "time: 1721853, epoch: 1, step: 329, outputs are [6.4805803]\n",
      "time: 1727145, epoch: 1, step: 330, outputs are [6.3485923]\n",
      "time: 1732533, epoch: 1, step: 331, outputs are [6.40997]\n",
      "time: 1737417, epoch: 1, step: 332, outputs are [6.885526]\n",
      "time: 1742374, epoch: 1, step: 333, outputs are [6.5640783]\n",
      "time: 1747275, epoch: 1, step: 334, outputs are [6.4115434]\n",
      "time: 1752669, epoch: 1, step: 335, outputs are [6.73445]\n",
      "time: 1757781, epoch: 1, step: 336, outputs are [6.4235477]\n",
      "time: 1762966, epoch: 1, step: 337, outputs are [6.7471538]\n",
      "time: 1768120, epoch: 1, step: 338, outputs are [6.377956]\n",
      "time: 1773262, epoch: 1, step: 339, outputs are [6.477994]\n",
      "time: 1778249, epoch: 1, step: 340, outputs are [6.5192366]\n",
      "time: 1783377, epoch: 1, step: 341, outputs are [6.5006604]\n",
      "time: 1788605, epoch: 1, step: 342, outputs are [6.517789]\n",
      "time: 1793673, epoch: 1, step: 343, outputs are [6.102659]\n",
      "time: 1798881, epoch: 1, step: 344, outputs are [6.167075]\n",
      "time: 1803974, epoch: 1, step: 345, outputs are [6.3687415]\n",
      "time: 1809004, epoch: 1, step: 346, outputs are [6.4404054]\n",
      "time: 1814116, epoch: 1, step: 347, outputs are [6.2691526]\n",
      "time: 1819176, epoch: 1, step: 348, outputs are [6.319193]\n",
      "time: 1824238, epoch: 1, step: 349, outputs are [6.514765]\n",
      "time: 1829478, epoch: 1, step: 350, outputs are [6.5706367]\n",
      "time: 1834557, epoch: 1, step: 351, outputs are [6.5595927]\n",
      "time: 1839537, epoch: 1, step: 352, outputs are [6.471496]\n",
      "time: 1844420, epoch: 1, step: 353, outputs are [6.444098]\n",
      "time: 1849195, epoch: 1, step: 354, outputs are [6.674508]\n",
      "time: 1854103, epoch: 1, step: 355, outputs are [6.557498]\n",
      "time: 1858847, epoch: 1, step: 356, outputs are [6.2327123]\n",
      "time: 1863506, epoch: 1, step: 357, outputs are [6.5150466]\n",
      "time: 1868206, epoch: 1, step: 358, outputs are [6.4047837]\n",
      "time: 1872959, epoch: 1, step: 359, outputs are [6.282652]\n",
      "time: 1877660, epoch: 1, step: 360, outputs are [6.6075587]\n",
      "time: 1882505, epoch: 1, step: 361, outputs are [6.4232116]\n",
      "time: 1887284, epoch: 1, step: 362, outputs are [6.401248]\n",
      "time: 1891994, epoch: 1, step: 363, outputs are [6.585981]\n",
      "time: 1896759, epoch: 1, step: 364, outputs are [6.4760303]\n",
      "time: 1901551, epoch: 1, step: 365, outputs are [6.49467]\n",
      "time: 1906271, epoch: 1, step: 366, outputs are [6.3084116]\n",
      "time: 1911506, epoch: 1, step: 367, outputs are [6.4468412]\n",
      "time: 1917055, epoch: 1, step: 368, outputs are [6.253628]\n",
      "time: 1922052, epoch: 1, step: 369, outputs are [6.452102]\n",
      "time: 1927164, epoch: 1, step: 370, outputs are [6.104666]\n",
      "time: 1932076, epoch: 1, step: 371, outputs are [6.059978]\n",
      "time: 1936835, epoch: 1, step: 372, outputs are [6.258493]\n",
      "time: 1941531, epoch: 1, step: 373, outputs are [6.1723423]\n",
      "time: 1946423, epoch: 1, step: 374, outputs are [6.209422]\n",
      "time: 1951188, epoch: 1, step: 375, outputs are [6.068753]\n",
      "time: 1955892, epoch: 1, step: 376, outputs are [6.415337]\n",
      "time: 1960596, epoch: 1, step: 377, outputs are [6.37968]\n",
      "time: 1965587, epoch: 1, step: 378, outputs are [6.3967915]\n",
      "time: 1970491, epoch: 1, step: 379, outputs are [6.5369463]\n",
      "time: 1975415, epoch: 1, step: 380, outputs are [6.4926605]\n",
      "time: 1980282, epoch: 1, step: 381, outputs are [6.2835793]\n",
      "time: 1985218, epoch: 1, step: 382, outputs are [6.470683]\n",
      "time: 1990148, epoch: 1, step: 383, outputs are [6.8147717]\n",
      "time: 1995186, epoch: 1, step: 384, outputs are [6.4929576]\n",
      "time: 2000319, epoch: 1, step: 385, outputs are [6.0961137]\n",
      "time: 2005539, epoch: 1, step: 386, outputs are [6.403662]\n",
      "time: 2010713, epoch: 1, step: 387, outputs are [6.3309703]\n",
      "time: 2015903, epoch: 1, step: 388, outputs are [6.073996]\n",
      "time: 2021140, epoch: 1, step: 389, outputs are [6.3645015]\n",
      "time: 2026308, epoch: 1, step: 390, outputs are [6.2042766]\n",
      "time: 2031378, epoch: 1, step: 391, outputs are [6.467943]\n",
      "time: 2036591, epoch: 1, step: 392, outputs are [6.488075]\n",
      "time: 2041464, epoch: 1, step: 393, outputs are [6.34752]\n",
      "time: 2046564, epoch: 1, step: 394, outputs are [6.3157167]\n",
      "time: 2051690, epoch: 1, step: 395, outputs are [6.1626415]\n",
      "time: 2056892, epoch: 1, step: 396, outputs are [6.2938776]\n",
      "time: 2061966, epoch: 1, step: 397, outputs are [6.2751174]\n",
      "time: 2067167, epoch: 1, step: 398, outputs are [5.9867578]\n",
      "time: 2072305, epoch: 1, step: 399, outputs are [6.207632]\n",
      "time: 2077427, epoch: 1, step: 400, outputs are [6.3212414]\n",
      "time: 2082329, epoch: 1, step: 401, outputs are [6.039558]\n",
      "time: 2087347, epoch: 1, step: 402, outputs are [6.1129284]\n",
      "time: 2092224, epoch: 1, step: 403, outputs are [6.185608]\n",
      "time: 2097642, epoch: 1, step: 404, outputs are [6.397872]\n",
      "time: 2102656, epoch: 1, step: 405, outputs are [6.4007635]\n",
      "time: 2107780, epoch: 1, step: 406, outputs are [6.3895326]\n",
      "time: 2113073, epoch: 1, step: 407, outputs are [6.297601]\n",
      "time: 2118448, epoch: 1, step: 408, outputs are [6.7558556]\n",
      "time: 2123478, epoch: 1, step: 409, outputs are [6.318312]\n",
      "time: 2128507, epoch: 1, step: 410, outputs are [6.2268286]\n",
      "time: 2133626, epoch: 1, step: 411, outputs are [6.15594]\n",
      "time: 2138657, epoch: 1, step: 412, outputs are [6.16042]\n",
      "time: 2143683, epoch: 1, step: 413, outputs are [6.4338255]\n",
      "time: 2148636, epoch: 1, step: 414, outputs are [6.12219]\n",
      "time: 2153745, epoch: 1, step: 415, outputs are [6.2700343]\n",
      "time: 2158888, epoch: 1, step: 416, outputs are [6.409865]\n",
      "time: 2163827, epoch: 1, step: 417, outputs are [6.2959743]\n",
      "time: 2168778, epoch: 1, step: 418, outputs are [6.227909]\n",
      "time: 2173582, epoch: 1, step: 419, outputs are [6.154038]\n",
      "time: 2178646, epoch: 1, step: 420, outputs are [6.2294245]\n",
      "time: 2183690, epoch: 1, step: 421, outputs are [6.038929]\n",
      "time: 2188728, epoch: 1, step: 422, outputs are [5.996931]\n",
      "time: 2193760, epoch: 1, step: 423, outputs are [6.1379857]\n",
      "time: 2198746, epoch: 1, step: 424, outputs are [6.0388227]\n",
      "time: 2203672, epoch: 1, step: 425, outputs are [6.353135]\n",
      "time: 2208655, epoch: 1, step: 426, outputs are [6.156523]\n",
      "time: 2213670, epoch: 1, step: 427, outputs are [6.2624726]\n",
      "time: 2218740, epoch: 1, step: 428, outputs are [6.4650035]\n",
      "time: 2223895, epoch: 1, step: 429, outputs are [6.275096]\n",
      "time: 2229115, epoch: 1, step: 430, outputs are [6.3888125]\n",
      "time: 2234562, epoch: 1, step: 431, outputs are [6.6118875]\n",
      "time: 2240297, epoch: 1, step: 432, outputs are [6.629164]\n",
      "time: 2245499, epoch: 1, step: 433, outputs are [6.1758585]\n",
      "time: 2250999, epoch: 1, step: 434, outputs are [6.3405933]\n",
      "time: 2256263, epoch: 1, step: 435, outputs are [6.10427]\n",
      "time: 2261197, epoch: 1, step: 436, outputs are [6.1641636]\n",
      "time: 2266249, epoch: 1, step: 437, outputs are [6.27277]\n",
      "time: 2271394, epoch: 1, step: 438, outputs are [6.1927743]\n",
      "time: 2276636, epoch: 1, step: 439, outputs are [6.2546544]\n",
      "time: 2281611, epoch: 1, step: 440, outputs are [6.387814]\n",
      "time: 2286697, epoch: 1, step: 441, outputs are [6.2245793]\n",
      "time: 2291609, epoch: 1, step: 442, outputs are [6.100354]\n",
      "time: 2297051, epoch: 1, step: 443, outputs are [5.8283415]\n",
      "time: 2302773, epoch: 1, step: 444, outputs are [5.985284]\n",
      "time: 2307918, epoch: 1, step: 445, outputs are [5.983184]\n",
      "time: 2313036, epoch: 1, step: 446, outputs are [6.3598375]\n",
      "time: 2318146, epoch: 1, step: 447, outputs are [6.276632]\n",
      "time: 2323377, epoch: 1, step: 448, outputs are [6.2867193]\n",
      "time: 2328778, epoch: 1, step: 449, outputs are [6.356862]\n",
      "time: 2334062, epoch: 1, step: 450, outputs are [6.1485643]\n",
      "time: 2339147, epoch: 1, step: 451, outputs are [6.1781707]\n",
      "time: 2344069, epoch: 1, step: 452, outputs are [6.2605805]\n",
      "time: 2349160, epoch: 1, step: 453, outputs are [6.3084936]\n",
      "time: 2354247, epoch: 1, step: 454, outputs are [6.3750415]\n",
      "time: 2359211, epoch: 1, step: 455, outputs are [6.2672086]\n",
      "time: 2364239, epoch: 1, step: 456, outputs are [5.9928637]\n",
      "time: 2369448, epoch: 1, step: 457, outputs are [5.9524283]\n",
      "time: 2374623, epoch: 1, step: 458, outputs are [6.0567837]\n",
      "time: 2379744, epoch: 1, step: 459, outputs are [6.2918587]\n",
      "time: 2384873, epoch: 1, step: 460, outputs are [6.1965623]\n",
      "time: 2389845, epoch: 1, step: 461, outputs are [6.4025717]\n",
      "time: 2394900, epoch: 1, step: 462, outputs are [6.643056]\n",
      "time: 2399938, epoch: 1, step: 463, outputs are [6.090358]\n",
      "time: 2405101, epoch: 1, step: 464, outputs are [6.066223]\n",
      "time: 2410330, epoch: 1, step: 465, outputs are [5.993143]\n",
      "time: 2415461, epoch: 1, step: 466, outputs are [6.1513195]\n",
      "time: 2420848, epoch: 1, step: 467, outputs are [6.152497]\n",
      "time: 2426055, epoch: 1, step: 468, outputs are [6.188432]\n",
      "time: 2431062, epoch: 1, step: 469, outputs are [6.241547]\n",
      "time: 2436207, epoch: 1, step: 470, outputs are [5.9585986]\n",
      "time: 2441226, epoch: 1, step: 471, outputs are [5.936092]\n",
      "time: 2446411, epoch: 1, step: 472, outputs are [6.4183125]\n",
      "time: 2451719, epoch: 1, step: 473, outputs are [6.192585]\n",
      "time: 2456770, epoch: 1, step: 474, outputs are [6.385209]\n",
      "time: 2461725, epoch: 1, step: 475, outputs are [6.2720146]\n",
      "time: 2467169, epoch: 1, step: 476, outputs are [6.1501036]\n",
      "time: 2472191, epoch: 1, step: 477, outputs are [6.1515765]\n",
      "time: 2477387, epoch: 1, step: 478, outputs are [6.304463]\n",
      "time: 2482540, epoch: 1, step: 479, outputs are [6.1327233]\n",
      "time: 2487524, epoch: 1, step: 480, outputs are [6.2617145]\n",
      "time: 2492587, epoch: 1, step: 481, outputs are [5.890622]\n",
      "time: 2497710, epoch: 1, step: 482, outputs are [5.841526]\n",
      "time: 2502818, epoch: 1, step: 483, outputs are [6.063698]\n",
      "time: 2507982, epoch: 1, step: 484, outputs are [6.485417]\n",
      "time: 2513234, epoch: 1, step: 485, outputs are [6.349572]\n",
      "time: 2518467, epoch: 1, step: 486, outputs are [6.3205667]\n",
      "time: 2523840, epoch: 1, step: 487, outputs are [5.9716287]\n",
      "time: 2528839, epoch: 1, step: 488, outputs are [6.154449]\n",
      "time: 2533986, epoch: 1, step: 489, outputs are [6.2760897]\n",
      "time: 2539180, epoch: 1, step: 490, outputs are [6.1221433]\n",
      "time: 2543983, epoch: 1, step: 491, outputs are [6.082199]\n",
      "time: 2549012, epoch: 1, step: 492, outputs are [5.8844733]\n",
      "time: 2554516, epoch: 1, step: 493, outputs are [6.238955]\n",
      "time: 2559444, epoch: 1, step: 494, outputs are [6.25138]\n",
      "time: 2564333, epoch: 1, step: 495, outputs are [6.5048623]\n",
      "time: 2569556, epoch: 1, step: 496, outputs are [5.9881573]\n",
      "time: 2574729, epoch: 1, step: 497, outputs are [6.0459943]\n",
      "time: 2579773, epoch: 1, step: 498, outputs are [6.1019864]\n",
      "time: 2585200, epoch: 1, step: 499, outputs are [6.214129]\n",
      "time: 2590477, epoch: 1, step: 500, outputs are [6.1548915]\n",
      "time: 2596546, epoch: 1, step: 501, outputs are [5.8367906]\n",
      "time: 2601662, epoch: 1, step: 502, outputs are [5.97193]\n",
      "time: 2606655, epoch: 1, step: 503, outputs are [6.3310227]\n",
      "time: 2611793, epoch: 1, step: 504, outputs are [6.3774915]\n",
      "time: 2616812, epoch: 1, step: 505, outputs are [6.423784]\n",
      "time: 2621758, epoch: 1, step: 506, outputs are [6.094614]\n",
      "time: 2626990, epoch: 1, step: 507, outputs are [6.211164]\n",
      "time: 2632197, epoch: 1, step: 508, outputs are [6.2475214]\n",
      "time: 2637410, epoch: 1, step: 509, outputs are [6.1917925]\n",
      "time: 2642592, epoch: 1, step: 510, outputs are [5.990575]\n",
      "time: 2647630, epoch: 1, step: 511, outputs are [5.992191]\n",
      "time: 2652671, epoch: 1, step: 512, outputs are [6.2387323]\n",
      "time: 2657986, epoch: 1, step: 513, outputs are [6.2756824]\n",
      "time: 2663158, epoch: 1, step: 514, outputs are [6.032233]\n",
      "time: 2668344, epoch: 1, step: 515, outputs are [6.076687]\n",
      "time: 2673473, epoch: 1, step: 516, outputs are [6.400595]\n",
      "time: 2678610, epoch: 1, step: 517, outputs are [6.0207314]\n",
      "time: 2683683, epoch: 1, step: 518, outputs are [5.8192387]\n",
      "time: 2689186, epoch: 1, step: 519, outputs are [6.208058]\n",
      "time: 2694092, epoch: 1, step: 520, outputs are [6.3186016]\n",
      "time: 2699121, epoch: 1, step: 521, outputs are [6.1269054]\n",
      "time: 2704140, epoch: 1, step: 522, outputs are [5.8938994]\n",
      "time: 2709098, epoch: 1, step: 523, outputs are [6.1837296]\n",
      "time: 2714187, epoch: 1, step: 524, outputs are [6.1676407]\n",
      "time: 2719364, epoch: 1, step: 525, outputs are [5.948138]\n",
      "time: 2724572, epoch: 1, step: 526, outputs are [6.2994657]\n",
      "time: 2730170, epoch: 1, step: 527, outputs are [6.266205]\n",
      "time: 2735404, epoch: 1, step: 528, outputs are [6.0933614]\n",
      "time: 2740637, epoch: 1, step: 529, outputs are [6.310413]\n",
      "time: 2745830, epoch: 1, step: 530, outputs are [6.2571344]\n",
      "time: 2750851, epoch: 1, step: 531, outputs are [5.8219824]\n",
      "time: 2756413, epoch: 1, step: 532, outputs are [6.126496]\n",
      "time: 2761626, epoch: 1, step: 533, outputs are [6.443913]\n",
      "time: 2766763, epoch: 1, step: 534, outputs are [5.8878407]\n",
      "time: 2772451, epoch: 1, step: 535, outputs are [6.240598]\n",
      "time: 2777897, epoch: 1, step: 536, outputs are [6.3227344]\n",
      "time: 2783252, epoch: 1, step: 537, outputs are [5.8793035]\n",
      "time: 2788568, epoch: 1, step: 538, outputs are [6.2329493]\n",
      "time: 2793741, epoch: 1, step: 539, outputs are [6.503048]\n",
      "time: 2798798, epoch: 1, step: 540, outputs are [6.0311246]\n",
      "time: 2803647, epoch: 1, step: 541, outputs are [6.202375]\n",
      "time: 2808794, epoch: 1, step: 542, outputs are [6.223512]\n",
      "time: 2813846, epoch: 1, step: 543, outputs are [6.003442]\n",
      "time: 2819107, epoch: 1, step: 544, outputs are [6.468198]\n",
      "time: 2824583, epoch: 1, step: 545, outputs are [6.0314355]\n",
      "time: 2829551, epoch: 1, step: 546, outputs are [6.2702317]\n",
      "time: 2834595, epoch: 1, step: 547, outputs are [6.175748]\n",
      "time: 2839559, epoch: 1, step: 548, outputs are [5.9965143]\n",
      "time: 2844546, epoch: 1, step: 549, outputs are [6.545656]\n",
      "time: 2849464, epoch: 1, step: 550, outputs are [6.209638]\n",
      "time: 2854218, epoch: 1, step: 551, outputs are [6.2239494]\n",
      "time: 2859047, epoch: 1, step: 552, outputs are [5.9771814]\n",
      "time: 2864212, epoch: 1, step: 553, outputs are [6.110432]\n",
      "time: 2869089, epoch: 1, step: 554, outputs are [6.3751]\n",
      "time: 2873968, epoch: 1, step: 555, outputs are [6.2225246]\n",
      "time: 2878979, epoch: 1, step: 556, outputs are [5.9684334]\n",
      "time: 2883967, epoch: 1, step: 557, outputs are [6.2454677]\n",
      "time: 2888765, epoch: 1, step: 558, outputs are [6.1305113]\n",
      "time: 2893688, epoch: 1, step: 559, outputs are [6.165003]\n",
      "time: 2898900, epoch: 1, step: 560, outputs are [6.183155]\n",
      "time: 2904049, epoch: 1, step: 561, outputs are [6.346615]\n",
      "time: 2909235, epoch: 1, step: 562, outputs are [6.1862507]\n",
      "time: 2914577, epoch: 1, step: 563, outputs are [6.461618]\n",
      "time: 2919699, epoch: 1, step: 564, outputs are [6.267165]\n",
      "time: 2924849, epoch: 1, step: 565, outputs are [6.2418537]\n",
      "time: 2930025, epoch: 1, step: 566, outputs are [6.1729984]\n",
      "time: 2935241, epoch: 1, step: 567, outputs are [6.1978645]\n",
      "time: 2940124, epoch: 1, step: 568, outputs are [6.1522765]\n",
      "time: 2945064, epoch: 1, step: 569, outputs are [6.237616]\n",
      "time: 2949921, epoch: 1, step: 570, outputs are [6.42913]\n",
      "time: 2955051, epoch: 1, step: 571, outputs are [6.1815476]\n",
      "time: 2960254, epoch: 1, step: 572, outputs are [6.2799945]\n",
      "time: 2965427, epoch: 1, step: 573, outputs are [6.4072247]\n",
      "time: 2970618, epoch: 1, step: 574, outputs are [6.198452]\n",
      "time: 2975842, epoch: 1, step: 575, outputs are [6.319978]\n",
      "time: 2980979, epoch: 1, step: 576, outputs are [6.4626126]\n",
      "time: 2986120, epoch: 1, step: 577, outputs are [6.277243]\n",
      "time: 2991128, epoch: 1, step: 578, outputs are [6.101521]\n",
      "time: 2996324, epoch: 1, step: 579, outputs are [6.3180943]\n",
      "time: 3001430, epoch: 1, step: 580, outputs are [6.5341935]\n",
      "time: 3006674, epoch: 1, step: 581, outputs are [6.2531815]\n",
      "time: 3011818, epoch: 1, step: 582, outputs are [6.473148]\n",
      "time: 3016911, epoch: 1, step: 583, outputs are [6.325686]\n",
      "time: 3022087, epoch: 1, step: 584, outputs are [6.33037]\n",
      "time: 3027281, epoch: 1, step: 585, outputs are [6.303995]\n",
      "time: 3032324, epoch: 1, step: 586, outputs are [6.428295]\n",
      "time: 3037607, epoch: 1, step: 587, outputs are [6.228737]\n",
      "time: 3042632, epoch: 1, step: 588, outputs are [6.6129384]\n",
      "time: 3047832, epoch: 1, step: 589, outputs are [6.53594]\n",
      "time: 3052949, epoch: 1, step: 590, outputs are [6.7012644]\n",
      "epoch time: 3053367.096 ms, per step time: 5175.198 ms\n",
      "time: 3058485, epoch: 2, step: 591, outputs are [5.7792215]\n",
      "time: 3063623, epoch: 2, step: 592, outputs are [5.747413]\n",
      "time: 3068571, epoch: 2, step: 593, outputs are [5.7131996]\n",
      "time: 3073713, epoch: 2, step: 594, outputs are [5.4335895]\n",
      "time: 3078777, epoch: 2, step: 595, outputs are [5.130587]\n",
      "time: 3083778, epoch: 2, step: 596, outputs are [5.591978]\n",
      "time: 3088711, epoch: 2, step: 597, outputs are [4.8457565]\n",
      "time: 3093948, epoch: 2, step: 598, outputs are [5.372339]\n",
      "time: 3099124, epoch: 2, step: 599, outputs are [5.1493335]\n",
      "time: 3104168, epoch: 2, step: 600, outputs are [5.045809]\n",
      "time: 3109239, epoch: 2, step: 601, outputs are [5.2202425]\n",
      "time: 3114331, epoch: 2, step: 602, outputs are [5.0485873]\n",
      "time: 3119478, epoch: 2, step: 603, outputs are [5.27816]\n",
      "time: 3124684, epoch: 2, step: 604, outputs are [4.884129]\n",
      "time: 3129872, epoch: 2, step: 605, outputs are [5.0689783]\n",
      "time: 3134995, epoch: 2, step: 606, outputs are [5.2136164]\n",
      "time: 3140006, epoch: 2, step: 607, outputs are [4.9241066]\n",
      "time: 3145090, epoch: 2, step: 608, outputs are [5.2649217]\n",
      "time: 3150351, epoch: 2, step: 609, outputs are [5.000725]\n",
      "time: 3155489, epoch: 2, step: 610, outputs are [4.8072004]\n",
      "time: 3160423, epoch: 2, step: 611, outputs are [5.4446673]\n",
      "time: 3165720, epoch: 2, step: 612, outputs are [5.078304]\n",
      "time: 3170818, epoch: 2, step: 613, outputs are [4.9206047]\n",
      "time: 3175932, epoch: 2, step: 614, outputs are [5.2961044]\n",
      "time: 3181189, epoch: 2, step: 615, outputs are [4.999879]\n",
      "time: 3187166, epoch: 2, step: 616, outputs are [4.904253]\n",
      "time: 3192468, epoch: 2, step: 617, outputs are [4.878755]\n",
      "time: 3197935, epoch: 2, step: 618, outputs are [5.1641483]\n",
      "time: 3203962, epoch: 2, step: 619, outputs are [5.243418]\n",
      "time: 3209029, epoch: 2, step: 620, outputs are [4.9395576]\n",
      "time: 3213959, epoch: 2, step: 621, outputs are [5.144737]\n",
      "time: 3218789, epoch: 2, step: 622, outputs are [5.2406588]\n",
      "time: 3223868, epoch: 2, step: 623, outputs are [5.3586683]\n",
      "time: 3228914, epoch: 2, step: 624, outputs are [5.0789523]\n",
      "time: 3234550, epoch: 2, step: 625, outputs are [5.07845]\n",
      "time: 3239818, epoch: 2, step: 626, outputs are [4.8074946]\n",
      "time: 3245227, epoch: 2, step: 627, outputs are [5.285582]\n",
      "time: 3250366, epoch: 2, step: 628, outputs are [5.4550624]\n",
      "time: 3255302, epoch: 2, step: 629, outputs are [5.0299625]\n",
      "time: 3260473, epoch: 2, step: 630, outputs are [4.7226825]\n",
      "time: 3265556, epoch: 2, step: 631, outputs are [4.9251485]\n",
      "time: 3270748, epoch: 2, step: 632, outputs are [5.018704]\n",
      "time: 3275894, epoch: 2, step: 633, outputs are [5.3323593]\n",
      "time: 3281167, epoch: 2, step: 634, outputs are [4.962727]\n",
      "time: 3286460, epoch: 2, step: 635, outputs are [4.808846]\n",
      "time: 3291568, epoch: 2, step: 636, outputs are [4.95425]\n",
      "time: 3296739, epoch: 2, step: 637, outputs are [5.1608615]\n",
      "time: 3301757, epoch: 2, step: 638, outputs are [5.4412355]\n",
      "time: 3306567, epoch: 2, step: 639, outputs are [5.3592367]\n",
      "time: 3311412, epoch: 2, step: 640, outputs are [4.8886385]\n",
      "time: 3316349, epoch: 2, step: 641, outputs are [4.8105764]\n",
      "time: 3321273, epoch: 2, step: 642, outputs are [4.988179]\n",
      "time: 3326168, epoch: 2, step: 643, outputs are [5.200082]\n",
      "time: 3331040, epoch: 2, step: 644, outputs are [5.256174]\n",
      "time: 3335918, epoch: 2, step: 645, outputs are [5.0185375]\n",
      "time: 3340958, epoch: 2, step: 646, outputs are [4.969682]\n",
      "time: 3346075, epoch: 2, step: 647, outputs are [4.792515]\n",
      "time: 3351232, epoch: 2, step: 648, outputs are [4.9000716]\n",
      "time: 3356331, epoch: 2, step: 649, outputs are [5.19951]\n",
      "time: 3361370, epoch: 2, step: 650, outputs are [5.622077]\n",
      "time: 3366620, epoch: 2, step: 651, outputs are [5.1164107]\n",
      "time: 3371676, epoch: 2, step: 652, outputs are [4.716835]\n",
      "time: 3376466, epoch: 2, step: 653, outputs are [4.864064]\n",
      "time: 3381506, epoch: 2, step: 654, outputs are [5.1604257]\n",
      "time: 3386646, epoch: 2, step: 655, outputs are [5.0561476]\n",
      "time: 3391429, epoch: 2, step: 656, outputs are [5.375939]\n",
      "time: 3396480, epoch: 2, step: 657, outputs are [5.157021]\n",
      "time: 3401477, epoch: 2, step: 658, outputs are [5.0007353]\n",
      "time: 3406545, epoch: 2, step: 659, outputs are [4.9243894]\n",
      "time: 3411663, epoch: 2, step: 660, outputs are [4.977028]\n",
      "time: 3416907, epoch: 2, step: 661, outputs are [5.150548]\n",
      "time: 3422092, epoch: 2, step: 662, outputs are [5.071238]\n",
      "time: 3427364, epoch: 2, step: 663, outputs are [5.2049913]\n",
      "time: 3432707, epoch: 2, step: 664, outputs are [5.311854]\n",
      "time: 3438109, epoch: 2, step: 665, outputs are [4.7937207]\n",
      "time: 3443194, epoch: 2, step: 666, outputs are [4.8166575]\n",
      "time: 3448440, epoch: 2, step: 667, outputs are [4.890938]\n",
      "time: 3453588, epoch: 2, step: 668, outputs are [5.2120686]\n",
      "time: 3458506, epoch: 2, step: 669, outputs are [5.124176]\n",
      "time: 3463572, epoch: 2, step: 670, outputs are [5.213214]\n",
      "time: 3468556, epoch: 2, step: 671, outputs are [5.4794793]\n",
      "time: 3473555, epoch: 2, step: 672, outputs are [5.36454]\n",
      "time: 3478531, epoch: 2, step: 673, outputs are [4.975867]\n",
      "time: 3483461, epoch: 2, step: 674, outputs are [5.0453057]\n",
      "time: 3488429, epoch: 2, step: 675, outputs are [4.8019624]\n",
      "time: 3493428, epoch: 2, step: 676, outputs are [4.867441]\n",
      "time: 3498419, epoch: 2, step: 677, outputs are [5.4552946]\n",
      "time: 3503432, epoch: 2, step: 678, outputs are [5.457839]\n",
      "time: 3508421, epoch: 2, step: 679, outputs are [5.363204]\n",
      "time: 3513350, epoch: 2, step: 680, outputs are [4.812052]\n",
      "time: 3518350, epoch: 2, step: 681, outputs are [4.9631114]\n",
      "time: 3523412, epoch: 2, step: 682, outputs are [4.8304157]\n",
      "time: 3528287, epoch: 2, step: 683, outputs are [5.3021283]\n",
      "time: 3533269, epoch: 2, step: 684, outputs are [4.9757347]\n",
      "time: 3538689, epoch: 2, step: 685, outputs are [5.0344048]\n",
      "time: 3544004, epoch: 2, step: 686, outputs are [5.301214]\n",
      "time: 3549153, epoch: 2, step: 687, outputs are [5.3955827]\n",
      "time: 3554557, epoch: 2, step: 688, outputs are [4.9053416]\n",
      "time: 3559717, epoch: 2, step: 689, outputs are [5.022834]\n",
      "time: 3565339, epoch: 2, step: 690, outputs are [4.970977]\n",
      "time: 3570865, epoch: 2, step: 691, outputs are [4.923861]\n",
      "time: 3576177, epoch: 2, step: 692, outputs are [5.3955455]\n",
      "time: 3581483, epoch: 2, step: 693, outputs are [5.7714376]\n",
      "time: 3586787, epoch: 2, step: 694, outputs are [5.34488]\n",
      "time: 3591908, epoch: 2, step: 695, outputs are [5.286006]\n",
      "time: 3597051, epoch: 2, step: 696, outputs are [5.069048]\n",
      "time: 3602077, epoch: 2, step: 697, outputs are [4.9164495]\n",
      "time: 3607223, epoch: 2, step: 698, outputs are [4.757172]\n",
      "time: 3612316, epoch: 2, step: 699, outputs are [5.091217]\n",
      "time: 3617335, epoch: 2, step: 700, outputs are [5.16135]\n",
      "time: 3622306, epoch: 2, step: 701, outputs are [5.062328]\n",
      "time: 3627445, epoch: 2, step: 702, outputs are [5.51013]\n",
      "time: 3632724, epoch: 2, step: 703, outputs are [5.23109]\n",
      "time: 3637622, epoch: 2, step: 704, outputs are [5.182072]\n",
      "time: 3642617, epoch: 2, step: 705, outputs are [4.8830423]\n",
      "time: 3647532, epoch: 2, step: 706, outputs are [5.264318]\n",
      "time: 3652437, epoch: 2, step: 707, outputs are [5.008748]\n",
      "time: 3657354, epoch: 2, step: 708, outputs are [5.017716]\n",
      "time: 3662239, epoch: 2, step: 709, outputs are [5.320202]\n",
      "time: 3667163, epoch: 2, step: 710, outputs are [5.387728]\n",
      "time: 3672481, epoch: 2, step: 711, outputs are [5.513933]\n",
      "time: 3678888, epoch: 2, step: 712, outputs are [5.6534]\n",
      "time: 3684800, epoch: 2, step: 713, outputs are [5.137783]\n",
      "time: 3690022, epoch: 2, step: 714, outputs are [4.8815145]\n",
      "time: 3695449, epoch: 2, step: 715, outputs are [5.158632]\n",
      "time: 3700644, epoch: 2, step: 716, outputs are [5.0452385]\n",
      "time: 3705703, epoch: 2, step: 717, outputs are [5.154879]\n",
      "time: 3710717, epoch: 2, step: 718, outputs are [5.246303]\n",
      "time: 3716247, epoch: 2, step: 719, outputs are [5.248491]\n",
      "time: 3721789, epoch: 2, step: 720, outputs are [5.4997964]\n",
      "time: 3727163, epoch: 2, step: 721, outputs are [5.368197]\n",
      "time: 3732854, epoch: 2, step: 722, outputs are [4.909814]\n",
      "time: 3738029, epoch: 2, step: 723, outputs are [5.229775]\n",
      "time: 3743150, epoch: 2, step: 724, outputs are [5.0776467]\n",
      "time: 3748118, epoch: 2, step: 725, outputs are [5.113651]\n",
      "time: 3753296, epoch: 2, step: 726, outputs are [5.2414074]\n",
      "time: 3758532, epoch: 2, step: 727, outputs are [5.466866]\n",
      "time: 3763877, epoch: 2, step: 728, outputs are [5.326319]\n",
      "time: 3769143, epoch: 2, step: 729, outputs are [5.428105]\n",
      "time: 3774403, epoch: 2, step: 730, outputs are [5.2120686]\n",
      "time: 3779721, epoch: 2, step: 731, outputs are [5.0590763]\n",
      "time: 3784824, epoch: 2, step: 732, outputs are [5.020722]\n",
      "time: 3790038, epoch: 2, step: 733, outputs are [5.00282]\n",
      "time: 3795293, epoch: 2, step: 734, outputs are [5.2816777]\n",
      "time: 3800552, epoch: 2, step: 735, outputs are [5.215668]\n",
      "time: 3805621, epoch: 2, step: 736, outputs are [5.0271864]\n",
      "time: 3810960, epoch: 2, step: 737, outputs are [5.321082]\n",
      "time: 3816320, epoch: 2, step: 738, outputs are [5.3974967]\n",
      "time: 3821748, epoch: 2, step: 739, outputs are [5.224963]\n",
      "time: 3826914, epoch: 2, step: 740, outputs are [5.2606883]\n",
      "time: 3832108, epoch: 2, step: 741, outputs are [5.0219283]\n",
      "time: 3837352, epoch: 2, step: 742, outputs are [5.109314]\n",
      "time: 3842686, epoch: 2, step: 743, outputs are [5.1255493]\n",
      "time: 3847942, epoch: 2, step: 744, outputs are [4.920718]\n",
      "time: 3853033, epoch: 2, step: 745, outputs are [5.2276597]\n",
      "time: 3858224, epoch: 2, step: 746, outputs are [5.6851354]\n",
      "time: 3863502, epoch: 2, step: 747, outputs are [5.4729514]\n",
      "time: 3868763, epoch: 2, step: 748, outputs are [5.2333646]\n",
      "time: 3873832, epoch: 2, step: 749, outputs are [5.567067]\n",
      "time: 3879055, epoch: 2, step: 750, outputs are [5.403945]\n",
      "time: 3883845, epoch: 2, step: 751, outputs are [5.0048695]\n",
      "time: 3888739, epoch: 2, step: 752, outputs are [4.6576796]\n",
      "time: 3893886, epoch: 2, step: 753, outputs are [4.918625]\n",
      "time: 3899241, epoch: 2, step: 754, outputs are [5.2137046]\n",
      "time: 3904262, epoch: 2, step: 755, outputs are [5.0258536]\n",
      "time: 3909422, epoch: 2, step: 756, outputs are [5.0543685]\n",
      "time: 3914421, epoch: 2, step: 757, outputs are [5.1433725]\n",
      "time: 3919513, epoch: 2, step: 758, outputs are [5.0195203]\n",
      "time: 3924527, epoch: 2, step: 759, outputs are [5.3376274]\n",
      "time: 3929559, epoch: 2, step: 760, outputs are [5.219677]\n",
      "time: 3934743, epoch: 2, step: 761, outputs are [5.2562923]\n",
      "time: 3939811, epoch: 2, step: 762, outputs are [4.950743]\n",
      "time: 3945472, epoch: 2, step: 763, outputs are [5.027681]\n",
      "time: 3951243, epoch: 2, step: 764, outputs are [5.1007414]\n",
      "time: 3957106, epoch: 2, step: 765, outputs are [5.0095224]\n",
      "time: 3962711, epoch: 2, step: 766, outputs are [4.942984]\n",
      "time: 3969069, epoch: 2, step: 767, outputs are [5.133141]\n",
      "time: 3974790, epoch: 2, step: 768, outputs are [5.276547]\n",
      "time: 3980601, epoch: 2, step: 769, outputs are [5.2987437]\n",
      "time: 3985838, epoch: 2, step: 770, outputs are [5.5403347]\n",
      "time: 3990787, epoch: 2, step: 771, outputs are [5.376732]\n",
      "time: 3995955, epoch: 2, step: 772, outputs are [5.532987]\n",
      "time: 4001171, epoch: 2, step: 773, outputs are [5.0073433]\n",
      "time: 4006181, epoch: 2, step: 774, outputs are [4.895809]\n",
      "time: 4011255, epoch: 2, step: 775, outputs are [4.943854]\n",
      "time: 4016488, epoch: 2, step: 776, outputs are [4.9315057]\n",
      "time: 4021504, epoch: 2, step: 777, outputs are [5.2091627]\n",
      "time: 4026820, epoch: 2, step: 778, outputs are [5.183392]\n",
      "time: 4032108, epoch: 2, step: 779, outputs are [5.129661]\n",
      "time: 4037594, epoch: 2, step: 780, outputs are [5.5359745]\n",
      "time: 4042980, epoch: 2, step: 781, outputs are [5.2444224]\n",
      "time: 4048194, epoch: 2, step: 782, outputs are [5.255461]\n",
      "time: 4053739, epoch: 2, step: 783, outputs are [5.053787]\n",
      "time: 4059415, epoch: 2, step: 784, outputs are [5.010031]\n",
      "time: 4064813, epoch: 2, step: 785, outputs are [4.962139]\n",
      "time: 4070128, epoch: 2, step: 786, outputs are [5.2081623]\n",
      "time: 4075246, epoch: 2, step: 787, outputs are [5.1963344]\n",
      "time: 4080368, epoch: 2, step: 788, outputs are [5.429096]\n",
      "time: 4085668, epoch: 2, step: 789, outputs are [5.446191]\n",
      "time: 4090718, epoch: 2, step: 790, outputs are [5.376704]\n",
      "time: 4095893, epoch: 2, step: 791, outputs are [5.627391]\n",
      "time: 4101013, epoch: 2, step: 792, outputs are [5.649679]\n",
      "time: 4106273, epoch: 2, step: 793, outputs are [4.9625535]\n",
      "time: 4111294, epoch: 2, step: 794, outputs are [4.8181643]\n",
      "time: 4116454, epoch: 2, step: 795, outputs are [5.1698318]\n",
      "time: 4121686, epoch: 2, step: 796, outputs are [4.9726467]\n",
      "time: 4126874, epoch: 2, step: 797, outputs are [5.221715]\n",
      "time: 4132538, epoch: 2, step: 798, outputs are [5.4202647]\n",
      "time: 4137789, epoch: 2, step: 799, outputs are [5.349837]\n",
      "time: 4143131, epoch: 2, step: 800, outputs are [5.2214394]\n",
      "time: 4148116, epoch: 2, step: 801, outputs are [5.5439487]\n",
      "time: 4153249, epoch: 2, step: 802, outputs are [5.537405]\n",
      "time: 4158417, epoch: 2, step: 803, outputs are [4.991138]\n",
      "time: 4163456, epoch: 2, step: 804, outputs are [5.1935053]\n",
      "time: 4168618, epoch: 2, step: 805, outputs are [5.2763233]\n",
      "time: 4173817, epoch: 2, step: 806, outputs are [5.280747]\n",
      "time: 4178878, epoch: 2, step: 807, outputs are [5.2325835]\n",
      "time: 4184188, epoch: 2, step: 808, outputs are [5.3502116]\n",
      "time: 4189221, epoch: 2, step: 809, outputs are [5.2577224]\n",
      "time: 4194710, epoch: 2, step: 810, outputs are [5.4466753]\n",
      "time: 4199727, epoch: 2, step: 811, outputs are [5.4370694]\n",
      "time: 4204578, epoch: 2, step: 812, outputs are [5.645129]\n",
      "time: 4209833, epoch: 2, step: 813, outputs are [5.5514193]\n",
      "time: 4215010, epoch: 2, step: 814, outputs are [4.979719]\n",
      "time: 4220176, epoch: 2, step: 815, outputs are [4.790019]\n",
      "time: 4225101, epoch: 2, step: 816, outputs are [4.9575267]\n",
      "time: 4230155, epoch: 2, step: 817, outputs are [5.1531157]\n",
      "time: 4235378, epoch: 2, step: 818, outputs are [5.352503]\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "train(train_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# parameter settings\n",
    "eval_cfg = edict({\n",
    "    'transformer_network': 'base',\n",
    "    'data_file': './data/test.mindrecord',\n",
    "    'test_source_file': './data/source_test.txt',\n",
    "    'model_file': './checkpoint/transformer-32_40-15_590.ckpt',  # Check whether files exist in the checkpoint folder.\n",
    "    'vocab_file': './data/ch_en_vocab.txt',\n",
    "    'token_file': './token-32-40.txt',\n",
    "    'pred_file': './pred-32-40.txt',\n",
    "    # -------------------mast same with the train config and the datsset------------------------\n",
    "    'seq_length': 40,\n",
    "    'vocab_size': 10067,\n",
    "    #-------------------------------------eval config-----------------------------\n",
    "    'batch_size': 32,\n",
    "    'max_position_embeddings': 40\n",
    "    # mast same with the train config\n",
    "})\n",
    "\n",
    "'''\n",
    "two kinds of transformer model version\n",
    "'''\n",
    "\n",
    "if eval_cfg.transformer_network == 'base':\n",
    "    transformer_net_cfg = TransformerConfig(\n",
    "        batch_size=eval_cfg.batch_size,\n",
    "        seq_length=eval_cfg.seq_length,\n",
    "        vocab_size=eval_cfg.vocab_size,\n",
    "        hidden_size=512,\n",
    "        num_hidden_layers=6,\n",
    "        num_attention_heads=8,\n",
    "        intermediate_size=2048,\n",
    "        hidden_act=\"relu\",\n",
    "        hidden_dropout_prob=0.0,\n",
    "        attention_probs_dropout_prob=0.0,\n",
    "        max_position_embeddings=eval_cfg.max_position_embeddings,\n",
    "        label_smoothing=0.1,\n",
    "        input_mask_from_dataset=True,\n",
    "        beam_width=4,\n",
    "        max_decode_length=eval_cfg.seq_length,\n",
    "        length_penalty_weight=1.0,\n",
    "        dtype=mstype.float32,\n",
    "        compute_type=mstype.float16)\n",
    "\n",
    "elif eval_cfg.transformer_network == 'large':\n",
    "    transformer_net_cfg = TransformerConfig(\n",
    "        batch_size=eval_cfg.batch_size,\n",
    "        seq_length=eval_cfg.seq_length,\n",
    "        vocab_size=eval_cfg.vocab_size,\n",
    "        hidden_size=1024,\n",
    "        num_hidden_layers=6,\n",
    "        num_attention_heads=16,\n",
    "        intermediate_size=4096,\n",
    "        hidden_act=\"relu\",\n",
    "        hidden_dropout_prob=0.0,\n",
    "        attention_probs_dropout_prob=0.0,\n",
    "        max_position_embeddings=eval_cfg.max_position_embeddings,\n",
    "        label_smoothing=0.1,\n",
    "        input_mask_from_dataset=True,\n",
    "        beam_width=4,\n",
    "        max_decode_length=80,\n",
    "        length_penalty_weight=1.0,\n",
    "        dtype=mstype.float32,\n",
    "        compute_type=mstype.float16)\n",
    "else:\n",
    "    raise Exception(\n",
    "        \"The src/eval_confige of transformer_network must base or large and same with the train_confige confige. Change the str/eval_confige file and try again!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# function for test eval\n",
    "class TransformerInferCell(nn.Cell):\n",
    "    def __init__(self, network):\n",
    "        super(TransformerInferCell, self).__init__(auto_prefix=False)\n",
    "        self.network = network\n",
    "\n",
    "    def construct(self, source_ids, source_mask):\n",
    "        predicted_ids = self.network(source_ids, source_mask)\n",
    "        return predicted_ids\n",
    "\n",
    "\n",
    "def load_weights(model_path):\n",
    "    if model_path.endswith(\".npz\"):\n",
    "        ms_ckpt = np.load(model_path)\n",
    "        is_npz = True\n",
    "    else:\n",
    "        ms_ckpt = load_checkpoint(model_path)\n",
    "        is_npz = False\n",
    "\n",
    "    weights = {}\n",
    "\n",
    "    for msname in ms_ckpt:\n",
    "        infer_name = msname\n",
    "\n",
    "        if \"tfm_decoder\" in msname:\n",
    "            infer_name = \"tfm_decoder.decoder.\" + infer_name\n",
    "\n",
    "        if is_npz:\n",
    "            weights[infer_name] = ms_ckpt[msname]\n",
    "        else:\n",
    "            weights[infer_name] = ms_ckpt[msname].data.asnumpy()\n",
    "\n",
    "    weights[\"tfm_decoder.decoder.tfm_embedding_lookup.embedding_table\"]= weights[\"tfm_embedding_lookup.embedding_table\"]\n",
    "\n",
    "    parameter_dict = {}\n",
    "\n",
    "    for name in weights:\n",
    "        parameter_dict[name] = Parameter(Tensor(weights[name]), name=name)\n",
    "    return parameter_dict\n",
    "\n",
    "\n",
    "def evaluate(cfg):\n",
    "    context.set_context(mode=context.GRAPH_MODE, device_target=\"GPU\",\n",
    "                        reserve_class_name_in_scope=False)\n",
    "\n",
    "    tfm_model = TransformerModel(config=transformer_net_cfg, is_training=False,\n",
    "                                 use_one_hot_embeddings=False)\n",
    "\n",
    "    print(cfg.model_file)\n",
    "    parameter_dict = load_weights(cfg.model_file)\n",
    "    load_param_into_net(tfm_model, parameter_dict)\n",
    "    tfm_infer = TransformerInferCell(tfm_model)\n",
    "    model = Model(tfm_infer)\n",
    "\n",
    "    tokenizer = tokenization.WhiteSpaceTokenizer(vocab_file=cfg.vocab_file)\n",
    "    dataset = load_dataset(batch_size=cfg.batch_size, data_file=cfg.data_file)\n",
    "    predictions = []\n",
    "    source_sents = []\n",
    "    target_sents = []\n",
    "    f2 = open(cfg.test_source_file, 'r', encoding='utf-8')\n",
    "\n",
    "    for batch in dataset.create_dict_iterator():\n",
    "        source_sents.append(batch[\"source_eos_ids\"])\n",
    "        target_sents.append(batch[\"target_eos_ids\"])\n",
    "        source_ids = Tensor(batch[\"source_eos_ids\"], mstype.int32)\n",
    "        source_mask = Tensor(batch[\"source_eos_mask\"], mstype.int32)\n",
    "        predicted_ids = model.predict(source_ids, source_mask)\n",
    "        batch_out = predicted_ids.asnumpy()\n",
    "\n",
    "        for i in range(transformer_net_cfg.batch_size):\n",
    "            if batch_out.ndim == 3:\n",
    "                batch_out = batch_out[:, 0]\n",
    "\n",
    "            token_ids = [str(x) for x in batch_out[i].tolist()]\n",
    "            token = \" \".join(token_ids)\n",
    "\n",
    "            token_ids = [int(x) for x in token.strip().split()]\n",
    "            tokens = tokenizer.convert_ids_to_tokens(token_ids)\n",
    "            sent = \" \".join(tokens)\n",
    "            sent = sent.split(\"<s>\")[-1]\n",
    "            sent = sent.split(\"</s>\")[0]\n",
    "\n",
    "            label_sent = f2.readline().strip() + '\\t'\n",
    "            print(\"source: {}\".format(label_sent))\n",
    "            print(\"result: {}\".format(sent.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# test eval\n",
    "evaluate(eval_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore(1.5)",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
